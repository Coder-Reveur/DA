{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a03992-5d60-4819-b0df-dba4a7e3f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a793a0-9f15-44b0-8163-7cc1adb19b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mail_data.csv') #Importing the data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c40fe-c24e-403d-b0fd-850febd88256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785f6c4-37d5-4844-a700-08eb9297afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.where((pd.notnull(df)), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969fe5f7-9977-40a9-aac1-009b780d0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05faba0-3586-4a87-8c90-801f18e4c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8182ec8-7eec-463e-a718-ff2788f0c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape #To see the number of rows & columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052dcd3-13e9-4c05-9877-d485b4406217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Category'] == 'spam', 'Category',] = 0\n",
    "data.loc[data['Category'] == 'ham', 'Category',] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61504e5d-52f4-475d-9210-df7dc947e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data['Message']\n",
    "Y= data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887d5c5-95c9-474a-80ac-69c37c04a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51229ba7-ae15-47f5-909a-8a89efbcdd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824d3c4-713a-4123-bbd5-b17830466fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state = 3)\n",
    "#0.2 means 80% training & 20% testing\n",
    "#Random is used in ML to get consistent result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4486dc-aeb1-42c6-89de-4fa75ad6d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf771cd-9f40-4c51-9a20-062d8ffcd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aec793-4a68-4cb0-b412-3f85dfe6d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "feature_extraction = TfidfVectorizer(min_df=1, stop_words='english', lowercase=True)\n",
    "#stop_words is here used to ignore those words which can be saely ignored wihtout changing the meaning of the sentene (eg: the, have, an, etc.)\n",
    "\n",
    "# Transform the training and test data\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "\n",
    "# Convert Y labels to integer\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf875c2-497f-45e8-a9e1-94eef62ea2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a8309-8c0e-4929-be43-37e295931b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be75ca-79e5-44f5-ab90-f4d20fac2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe78b85-18d9-4a9c-b01f-342f3ecab9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the logisticregression data with the training data\n",
    "model.fit(X_train_features,Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b2be2-4c37-4259-b701-946a0a45af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model accuracy\n",
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)\n",
    "\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d6c35-9fa3-4fda-a3ac-e735f7cc5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy on Training Data: {accuracy_on_training_data * 100:.2f}%\")\n",
    "print(f\"Accuracy on Test Data: {accuracy_on_test_data * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2b9f7-7af8-4b4c-9a8c-9e6209451019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with custom input\n",
    "input_your_mail = [\n",
    "    \"This is the 2nd time we have tried to contact you. You have won the Rs 200000 prize. To claim is easy, just call\"\n",
    "]\n",
    "\n",
    "# Transform the input text\n",
    "input_data_features = feature_extraction.transform(input_your_mail)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(input_data_features)\n",
    "\n",
    "# Output the result\n",
    "if prediction[0] == 1:\n",
    "    print('Ham mail')\n",
    "else:\n",
    "    print('Spam mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c4450-a705-4297-b9f6-06514e06b4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82915cc3-93d6-44e3-a5dd-cc49ed92eabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d847a7-6dd6-4a1f-87d2-a1db082452e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff9037-86f7-4f62-acc9-8da5f66f877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b834e36-9c40-4fba-937c-87f827d80ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Spam vs. Ham\n",
    "category_counts = data['Category'].value_counts()\n",
    "print(category_counts)\n",
    "\n",
    "# Average message length by category\n",
    "data['Message_Length'] = data['Message'].apply(len)\n",
    "avg_length = data.groupby('Category')['Message_Length'].mean()\n",
    "print(avg_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ea38c-4cea-4658-b4b5-82211c38ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bar plot for category distribution\n",
    "category_counts.plot(kind='bar', color=['green', 'red'])\n",
    "plt.title('Spam vs Ham Distribution')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=['Ham', 'Spam'], rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for message length\n",
    "sns.boxplot(x='Category', y='Message_Length', data=data)\n",
    "plt.title('Message Length by Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a25d3-f12a-4beb-892f-73744d3dd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keyword Analysis \n",
    "#Identifying the most frequently used words in spam vs. ham messages using TfidfVectorizer or Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bea8d-1bc8-47ce-a30c-bb2adeb5f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create a function to extract common words\n",
    "def common_words(messages, top_n=10):\n",
    "    all_words = ' '.join(messages).split()\n",
    "    return Counter(all_words).most_common(top_n)\n",
    "\n",
    "# Get top words in spam and ham\n",
    "spam_words = common_words(data[data['Category'] == 0]['Message'])\n",
    "ham_words = common_words(data[data['Category'] == 1]['Message'])\n",
    "\n",
    "print(\"Top words in Spam:\", spam_words)\n",
    "print(\"Top words in Ham:\", ham_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69779a-b549-44c2-b111-53ae71d98e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "spam_text = ' '.join(data[data['Category'] == 0]['Message'])\n",
    "ham_text = ' '.join(data[data['Category'] == 1]['Message'])\n",
    "\n",
    "spam_wordcloud = WordCloud(width=800, height=400, background_color='red').generate(spam_text)\n",
    "ham_wordcloud = WordCloud(width=800, height=400, background_color='green').generate(ham_text)\n",
    "\n",
    "# Spam WordCloud\n",
    "plt.imshow(spam_wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Spam WordCloud\")\n",
    "plt.show()\n",
    "\n",
    "# Ham WordCloud\n",
    "plt.imshow(ham_wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Ham WordCloud\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9e32f-00aa-407d-86ee-ac831d232684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing Message Length Distribution\n",
    "#Examine how message length varies across spam and ham. Longer messages could have a pattern worth analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e84ea6-8834-4958-9ded-9baba0a24c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of message lengths by category\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(data=data, x='Message_Length', hue='Category', bins=30, kde=True, palette='coolwarm')\n",
    "plt.title('Message Length Distribution by Category')\n",
    "plt.xlabel('Message Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938ac75-5ee5-4f24-87cd-e34ca88b80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character-Based Features\n",
    "#Calculate and compare features like:\n",
    "#Number of uppercase letters (often used in spam for emphasis).\n",
    "#Special character count (e.g., $, !, #)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc132d-03a4-47f1-b159-84c589f2c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "data['Uppercase_Count'] = data['Message'].apply(lambda x: sum(1 for char in x if char.isupper()))\n",
    "data['Special_Char_Count'] = data['Message'].apply(lambda x: sum(1 for char in x if char in '!@#$%^&*'))\n",
    "\n",
    "# Compare across categories\n",
    "print(data.groupby('Category')[['Uppercase_Count', 'Special_Char_Count']].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c27aab-a265-4c49-8aa3-c9cd81384c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for uppercase letter counts\n",
    "sns.boxplot(x='Category', y='Uppercase_Count', data=data)\n",
    "plt.title('Uppercase Letter Count by Category')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for special character counts\n",
    "sns.boxplot(x='Category', y='Special_Char_Count', data=data)\n",
    "plt.title('Special Character Count by Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef6537-23e1-4751-83f5-8e412b6e8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation Enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc9ca4-3961-43bd-9feb-20f03bc4cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61f876-4546-4b8a-9abb-81e299bb65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_test, prediction_on_test_data)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Spam', 'Ham'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffee191-3c91-4778-8472-2ed51b82a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. Precision, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2bd92-f503-4e3a-870d-232a789e9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(Y_test, prediction_on_test_data, target_names=['Spam', 'Ham'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0822a-cd22-4b97-9445-6ab3cb5fa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance Analysis\n",
    "#Identifying which features (words) contribute the most to spam classification using the coefficients from the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee6757-e235-4448-9024-51fb1aa6a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the model\n",
    "feature_names = feature_extraction.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Combine feature names and their importance scores\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': coefficients})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Top 10 positive and negative features\n",
    "print(\"Top 10 Spam Indicators:\\n\", feature_importance.head(10))\n",
    "print(\"Top 10 Ham Indicators:\\n\", feature_importance.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53a48a-197b-45bc-ad6f-f0c3ad28f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for top spam indicators\n",
    "top_spam_features = feature_importance.head(10)\n",
    "top_spam_features.plot(kind='bar', x='Feature', y='Importance', legend=False, color='red')\n",
    "plt.title('Top Words Indicating Spam')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabbcaa-a8af-4728-acd6-74052c21b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experimenting with Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a3278-d534-4de5-b942-7f04199bffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f8d98-e41c-4f4b-a7dd-cfe700630d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_features, Y_train)\n",
    "\n",
    "# Evaluate\n",
    "rf_prediction = rf_model.predict(X_test_features)\n",
    "rf_accuracy = accuracy_score(Y_test, rf_prediction)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60a032-9165-4482-9b82-92069565e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e406fd-a7ef-4b5f-b80b-ab5dd7916320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_features, Y_train)\n",
    "\n",
    "# Evaluate\n",
    "svm_prediction = svm_model.predict(X_test_features)\n",
    "svm_accuracy = accuracy_score(Y_test, svm_prediction)\n",
    "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d109b61-1748-4cb4-ae0b-219267f98db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33668d-7e38-45f2-8068-f5aee5b746b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect accuracy scores\n",
    "model_accuracies = {\n",
    "    \"Logistic Regression\": accuracy_on_test_data,\n",
    "    \"Random Forest\": rf_accuracy,\n",
    "    \"SVM\": svm_accuracy,\n",
    "}\n",
    "\n",
    "# Print model performances\n",
    "print(\"Model Performance Comparison:\")\n",
    "for model, accuracy in model_accuracies.items():\n",
    "    print(f\"{model}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Bar plot for model comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(model_accuracies.keys(), [v * 100 for v in model_accuracies.values()], color=['blue', 'green', 'orange'])\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d01b8b-d4e4-41f6-a600-7fbf0b3048f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32609f76-790d-4ffc-9a16-9bf36d946ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10], \n",
    "    'kernel': ['linear', 'rbf'], \n",
    "    'gamma': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train_features, Y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Test with best model\n",
    "best_svm = grid_search.best_estimator_\n",
    "best_svm_accuracy = accuracy_score(Y_test, best_svm.predict(X_test_features))\n",
    "print(f\"Best SVM Test Accuracy: {best_svm_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576f3eb-b542-4ac3-bd99-b316cdb67bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de6e63-b606-460b-ab4d-58c44a27f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation on the best model\n",
    "scores = cross_val_score(best_svm, X_train_features, Y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Scores: {scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(scores) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556f3c3-3ec5-4631-84f4-d11607d73ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f5c18-fe2e-479c-b13a-c852855fd818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only the spam messages from the dataset. Transform the text data into numerical vectors using the TfidfVectorizer.\n",
    "#Applying K-Means Clustering\n",
    "#Using the KMeans algorithm to group similar spam messages into clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56615a-2430-454c-9f6d-69f328703960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Filter spam messages\n",
    "spam_messages = data[data['Category'] == 0]['Message']\n",
    "\n",
    "# Vectorize the spam messages using TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=500)  # Limit features for better clustering\n",
    "spam_vectors = tfidf.fit_transform(spam_messages)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "num_clusters = 5  # Adjust based on your preference\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(spam_vectors)\n",
    "\n",
    "# Get cluster labels\n",
    "spam_messages_clustered = pd.DataFrame({\n",
    "    'Message': spam_messages.values,\n",
    "    'Cluster': kmeans.labels_\n",
    "})\n",
    "\n",
    "# Display sample messages for each cluster\n",
    "for cluster in range(num_clusters):\n",
    "    print(f\"\\nCluster {cluster} Messages:\")\n",
    "    print(spam_messages_clustered[spam_messages_clustered['Cluster'] == cluster].head(5)['Message'].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff47dc-9b5f-4a43-b38f-79638e6cbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f089bd9-fb3a-42e1-a353-2087a8d018a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. Elbow Method for Optimal Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e680035-dc9c-469b-bc9f-6849bc24328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Determine the optimal number of clusters\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "cluster_range = range(2, 11)\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(spam_vectors)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(spam_vectors, kmeans.labels_))\n",
    "\n",
    "# Plot inertia and silhouette scores\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Elbow plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(cluster_range, inertia, marker='o')\n",
    "plt.title('Elbow Method: Inertia')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "\n",
    "# Silhouette score plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(cluster_range, silhouette_scores, marker='o', color='red')\n",
    "plt.title('Silhouette Score')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee65e5d-e031-47e8-a742-44ad4745571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. Word Cloud for Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c9218-4f9f-47b1-ae5f-c73b182261d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_messages = spam_messages_clustered[spam_messages_clustered['Cluster'] == cluster]['Message']\n",
    "    cluster_text = ' '.join(cluster_messages)\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(cluster_text)\n",
    "    \n",
    "    # Plot the word cloud\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Cluster {cluster} Word Cloud\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333f73b-1d27-4731-b7ac-c7318713bd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
